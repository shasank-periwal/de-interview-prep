{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOINS | LIT | COALESCE | UNION | INTERSECT | withColumnRenamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import coalesce, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/14 16:11:11 WARN Utils: Your hostname, shasankperiwal resolves to a loopback address: 127.0.1.1; using 192.168.20.45 instead (on interface wlp0s20f3)\n",
      "25/01/14 16:11:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/14 16:11:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "conf = pyspark.SparkConf().setAppName(\"joinsspark\").setMaster(\"local\")\n",
    "sc = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [(1, \"John\"),\n",
    "         (2, \"Jane\"),\n",
    "         (3, \"Alice\")]\n",
    "\n",
    "data2 = [(1, \"Math\"),\n",
    "         (2, \"Science\"),\n",
    "         (4, \"History\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = sc.createDataFrame(data1, [\"id\", \"name\"])\n",
    "df2 = sc.createDataFrame(data2, [\"id\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  1| John|\n",
      "|  2| Jane|\n",
      "|  3|Alice|\n",
      "+---+-----+\n",
      "\n",
      "+---+-------+\n",
      "| id|   name|\n",
      "+---+-------+\n",
      "|  1|   Math|\n",
      "|  2|Science|\n",
      "|  4|History|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+\n",
      "| id| name|   name|\n",
      "+---+-----+-------+\n",
      "|  1| John|   Math|\n",
      "|  3|Alice|   null|\n",
      "|  2| Jane|Science|\n",
      "+---+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "left_df = df1.join(df2, on=\"id\", how=\"left\")\n",
    "left_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|  id|   name|\n",
      "+----+-------+\n",
      "|   1|   Math|\n",
      "|   2|Science|\n",
      "|null|History|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "right_df = df1.join(df2, df1.id == df2.id, \"right\")\n",
    "right_df.select(df1[\"id\"], df2[\"name\"]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----------+-------+\n",
      "|identifier|name|identifier|   name|\n",
      "+----------+----+----------+-------+\n",
      "|         1|John|         1|   Math|\n",
      "|         2|Jane|         2|Science|\n",
      "|      null|null|         4|History|\n",
      "+----------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "right_df.withColumnRenamed(\"id\", \"identifier\").show()\n",
    "# .withColumnRenamed(df2[\"name\"], \"subject\")\n",
    "# new_df.select(\"identifier\", coalesce(\"subject\", \"none\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|identifier|subject|\n",
      "+----------+-------+\n",
      "|         1|   John|\n",
      "|         2|   Jane|\n",
      "|      null|   none|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = right_df.select(df1[\"id\"], coalesce(df1[\"name\"], lit(\"none\")).alias(\"subject\")).withColumnRenamed(\"id\", \"identifier\")\n",
    "# .withColumnRenamed(\"name\", \"subject\") this doesn't work because the column name is not the same\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [(1, \"John\"),\n",
    "         (2, \"Jane\"),\n",
    "         (3, \"Alice\")]\n",
    "\n",
    "data2 = [(3, \"Alice\"),\n",
    "         (4, \"Bob\"),\n",
    "         (5, \"Charlie\")]\n",
    "\n",
    "df1 = sc.createDataFrame(data1, [\"ID\", \"Name\"])\n",
    "df2 = sc.createDataFrame(data2, [\"ID\", \"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| ID|   Name|\n",
      "+---+-------+\n",
      "|  1|   John|\n",
      "|  2|   Jane|\n",
      "|  3|  Alice|\n",
      "|  3|  Alice|\n",
      "|  4|    Bob|\n",
      "|  5|Charlie|\n",
      "+---+-------+\n",
      "\n",
      "+---+-------+\n",
      "| ID|   Name|\n",
      "+---+-------+\n",
      "|  1|   John|\n",
      "|  2|   Jane|\n",
      "|  3|  Alice|\n",
      "|  3|  Alice|\n",
      "|  4|    Bob|\n",
      "|  5|Charlie|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df2).show()\n",
    "# Both work same in spark\n",
    "df1.unionAll(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| ID| Name|\n",
      "+---+-----+\n",
      "|  3|Alice|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.intersect(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| ID|Name|\n",
      "+---+----+\n",
      "|  2|Jane|\n",
      "|  1|John|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.subtract(df2).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
